id is:ye7bjx4d
Launching wandb...
/home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
[36m(pid=22175)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22175)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m(pid=22180)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22180)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m(pid=22174)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22174)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m(pid=22177)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22177)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m(pid=22179)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22179)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m(pid=22176)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22176)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m(pid=22178)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22178)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m(pid=22181)[39m /home/tho/anaconda3/envs/scrimp/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
[36m(pid=22181)[39m   warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
[36m[1m(scheduler +22s)[39m[22m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.
[33m[1m(scheduler +22s)[39m[22m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.0588}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
2024-03-13 02:44:11,226	WARNING worker.py:1228 -- The actor or task with ID ffffffffffffffff12d9b75f03d5a8d3c780f84c01000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.
Required resources for this actor or task: {CPU: 1.000000}, {GPU: 0.058800}
Available resources on this node: {0.000000/8.000000 CPU, 331937880.029297 GiB/331937880.029297 GiB memory, 0.529600/1.000000 GPU, 165968939.990234 GiB/165968939.990234 GiB object_store_memory, 1.000000/1.000000 node:172.21.165.112}
In total there are 0 pending tasks and 8 pending actors on this node.
[33m[1m(scheduler +57s)[39m[22m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.0588}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m[1m(scheduler +1m32s)[39m[22m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.0588}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m[1m(scheduler +2m7s)[39m[22m Warning: The following resource request cannot be scheduled right now: {'GPU': 0.0588, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m[1m(scheduler +2m42s)[39m[22m Warning: The following resource request cannot be scheduled right now: {'GPU': 0.0588, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
CTRL-C pressed. killing remote workers
Saving Final Model !
Traceback (most recent call last):
  File "driver.py", line 388, in <module>
    main()
  File "driver.py", line 294, in main
    "reward": eval_performance_dict['per_r']}
UnboundLocalError: local variable 'eval_performance_dict' referenced before assignment
Traceback (most recent call last):
  File "driver.py", line 388, in <module>
    main()
  File "driver.py", line 294, in main
    "reward": eval_performance_dict['per_r']}
UnboundLocalError: local variable 'eval_performance_dict' referenced before assignment